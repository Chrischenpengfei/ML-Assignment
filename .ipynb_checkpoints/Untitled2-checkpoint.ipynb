{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import scipy\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Define Subset\n",
    "test_id = test['id']\n",
    "target = train['target']\n",
    "\n",
    "#drop target and id from train, as it is not a feature.\n",
    "train.drop(['target', 'id'], axis=1, inplace=True) \n",
    "test.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bin_3 and bin_4 to numeric data\n",
    "bin_dict = {'T':1, 'F':0, 'Y':1, 'N':0}\n",
    "\n",
    "# Maping the category values in bin dict\n",
    "train['bin_3'] = train['bin_3'].map(bin_dict)\n",
    "train['bin_4'] = train['bin_4'].map(bin_dict)\n",
    "test['bin_3'] = test['bin_3'].map(bin_dict)\n",
    "test['bin_4'] = test['bin_4'].map(bin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seting the orders of our ordinal features\n",
    "ord_1 = CategoricalDtype(categories=['Novice', 'Contributor','Expert', \n",
    "                                     'Master', 'Grandmaster'], ordered=True)\n",
    "ord_2 = CategoricalDtype(categories=['Freezing', 'Cold', 'Warm', 'Hot',\n",
    "                                     'Boiling Hot', 'Lava Hot'], ordered=True)\n",
    "ord_3 = CategoricalDtype(categories=['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "                                     'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o'], ordered=True)\n",
    "ord_4 = CategoricalDtype(categories=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I',\n",
    "                                     'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "                                     'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming ordinal Features\n",
    "train.ord_1 = train.ord_1.astype(ord_1)\n",
    "train.ord_2 = train.ord_2.astype(ord_2)\n",
    "train.ord_3 = train.ord_3.astype(ord_3)\n",
    "train.ord_4 = train.ord_4.astype(ord_4)\n",
    "\n",
    "# test dataset\n",
    "test.ord_1 = test.ord_1.astype(ord_1)\n",
    "test.ord_2 = test.ord_2.astype(ord_2)\n",
    "test.ord_3 = test.ord_3.astype(ord_3)\n",
    "test.ord_4 = test.ord_4.astype(ord_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geting the codes of ordinal categoy's - train\n",
    "train.ord_1 = train.ord_1.cat.codes\n",
    "train.ord_2 = train.ord_2.cat.codes\n",
    "train.ord_3 = train.ord_3.cat.codes\n",
    "train.ord_4 = train.ord_4.cat.codes\n",
    "\n",
    "# Geting the codes of ordinal categoy's - test\n",
    "test.ord_1 = test.ord_1.cat.codes\n",
    "test.ord_2 = test.ord_2.cat.codes\n",
    "test.ord_3 = test.ord_3.cat.codes\n",
    "test.ord_4 = test.ord_4.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train&test data set for OHE\n",
    "all_data = pd.concat((train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE by using pandas.get_dummy\n",
    "encoded=pd.get_dummies(all_data, columns=all_data.columns, sparse=True)\n",
    "# Convert to sparse data structure to avoid memory issue when train data later\n",
    "encoded=encoded.sparse.to_coo().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data to train and test seperatly\n",
    "train_ohe = encoded[:len(train)]\n",
    "test_ohe = encoded[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using logistic regression with \"liblinear\" solver and C value as 0.1 we will tune the C value later with optuna\n",
    "model=LogisticRegression(C=0.1, solver=\"liblinear\", max_iter=10000)\n",
    "model.fit(train_ohe, target)\n",
    "pred=model.predict_proba(test_ohe)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8035356471423679\n"
     ]
    }
   ],
   "source": [
    "# scoring by roc_auc. because kaggle scoring submission by roc_auc\n",
    "score=cross_val_score(model, train_ohe, target, scoring='roc_auc', n_jobs=-1).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-28 01:12:49,339] Finished trial#0 with value: -0.6269912557824503 with parameters: {'C': 8.36495811733918e-07}. Best is trial#0 with value: -0.6269912557824503.\n",
      "[I 2020-04-28 01:12:50,567] Finished trial#1 with value: -0.6374593926169917 with parameters: {'C': 1.474885074500612e-06}. Best is trial#1 with value: -0.6374593926169917.\n",
      "[I 2020-04-28 01:12:51,499] Finished trial#2 with value: -0.6162433304956878 with parameters: {'C': 2.7350116584933465e-07}. Best is trial#1 with value: -0.6374593926169917.\n",
      "[I 2020-04-28 01:13:07,086] Finished trial#3 with value: -0.8009083710430895 with parameters: {'C': 0.41448134018812627}. Best is trial#3 with value: -0.8009083710430895.\n",
      "[I 2020-04-28 01:13:11,302] Finished trial#4 with value: -0.7942049218948997 with parameters: {'C': 0.013012229791217578}. Best is trial#3 with value: -0.8009083710430895.\n",
      "[I 2020-04-28 01:13:11,905] Finished trial#5 with value: -0.610964589780365 with parameters: {'C': 2.3135971790117303e-08}. Best is trial#3 with value: -0.8009083710430895.\n",
      "[I 2020-04-28 01:13:40,328] Finished trial#6 with value: -0.7903868040485188 with parameters: {'C': 4.177205114834047}. Best is trial#3 with value: -0.8009083710430895.\n",
      "[I 2020-04-28 01:14:09,248] Finished trial#7 with value: -0.7915912676016961 with parameters: {'C': 3.0685801617895705}. Best is trial#3 with value: -0.8009083710430895.\n",
      "[I 2020-04-28 01:14:09,885] Finished trial#8 with value: -0.6105991448252006 with parameters: {'C': 6.338029157420841e-09}. Best is trial#3 with value: -0.8009083710430895.\n",
      "[I 2020-04-28 01:14:12,174] Finished trial#9 with value: -0.7721341546077978 with parameters: {'C': 0.0020502122634695223}. Best is trial#3 with value: -0.8009083710430895.\n",
      "[I 2020-04-28 01:14:22,876] Finished trial#10 with value: -0.8034786442446776 with parameters: {'C': 0.1550436025302437}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:14:31,197] Finished trial#11 with value: -0.8032660731734701 with parameters: {'C': 0.07871624042275241}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:14:36,808] Finished trial#12 with value: -0.7994286312527826 with parameters: {'C': 0.027153791967630597}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:14:37,921] Finished trial#13 with value: -0.7302902415715629 with parameters: {'C': 0.00010059167573885672}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:14:49,257] Finished trial#14 with value: -0.8032552493263253 with parameters: {'C': 0.18441487936786533}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:14:50,745] Finished trial#15 with value: -0.7446662185131381 with parameters: {'C': 0.0002981517783990225}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:15:03,805] Finished trial#16 with value: -0.8025466321898109 with parameters: {'C': 0.2557587397020895}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:15:39,010] Finished trial#17 with value: -0.7878662674171564 with parameters: {'C': 8.895581037137232}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:15:41,692] Finished trial#18 with value: -0.7790396753538409 with parameters: {'C': 0.00334926593252242}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:15:42,615] Finished trial#19 with value: -0.7004096204680449 with parameters: {'C': 1.3122366338578797e-05}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:15:50,575] Finished trial#20 with value: -0.8029381605421282 with parameters: {'C': 0.06625866939365574}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:16:01,772] Finished trial#21 with value: -0.8033920465119285 with parameters: {'C': 0.1674603898694084}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:16:22,109] Finished trial#22 with value: -0.7965490999848289 with parameters: {'C': 1.058883977298162}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:16:24,244] Finished trial#23 with value: -0.7704046358278498 with parameters: {'C': 0.0018201562571817471}. Best is trial#10 with value: -0.8034786442446776.\n",
      "[I 2020-04-28 01:16:29,122] Finished trial#24 with value: -0.7950530141073104 with parameters: {'C': 0.01440476205739463}. Best is trial#10 with value: -0.8034786442446776.\n"
     ]
    }
   ],
   "source": [
    "# tune C \n",
    "def objective(trial):\n",
    "    C=trial.suggest_loguniform('C', 10e-10, 10)\n",
    "    model=LogisticRegression(C=C,max_iter=10000, solver='liblinear')\n",
    "    score=-cross_val_score(model, train_ohe, target, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    return score\n",
    "\n",
    "study=optuna.create_study()\n",
    "study.optimize(objective, n_trials=50)\n",
    "tuned_C=study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(C=tuned_C['C'], solver=\"liblinear\", max_iter=10000)\n",
    "model.fit(train_ohe, target)\n",
    "pred=model.predict_proba(test_ohe)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "score=cross_val_score(model, train_ohe, target, scoring=\"roc_auc\")[\"test_score\"].mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_id, 'target': pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
